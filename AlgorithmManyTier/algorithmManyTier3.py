import requests
from bs4 import BeautifulSoup
import json

algorithms = {'0-1 너비 우선 탐색': 0, '2-sat': 0, '3차원 기하학': 0, '4차원 이상의 기하학': 0, 'a*': 0, 'Aliens 트릭': 0,
              'Heavy-light 분할': 0, 'KMP': 0, "mo's": 0, 'utf-8 입력 처리': 0, 'z': 0, '가우스 소거법': 0,
              '가장 긴 증가하는 부분 수열: O(n log n)': 0, '값 / 좌표 압축': 0, '강한 연결 요소': 0, '게임 이론': 0, '경사 하강법': 0, '고속 푸리에 변환': 0,
              '구현': 0, '그래프 이론': 0, '그래프 탐색': 0, '그리디 알고리즘': 0, '그린 정리': 0, '기댓값의 선형성': 0, '기하학': 0, '깊이 우선 탐색': 0,
              '너비 우선 탐색': 0, '누적 합': 0, '느리게 갱신되는 세그먼트 트리': 0, '다각형의 넓이': 0, '다이나믹 프로그래밍': 0, '다중 대입값 계산': 0,
              '다차원 세그먼트 트리': 0, '다항식 보간법': 0, '단절점과 단절선': 0, '단조 큐를 이용한 최적화': 0, '담금질 기법': 0, '데이크스트라': 0, '데카르트 트리': 0,
              '덱': 0, '덱을 이용한 다이나믹 프로그래밍': 0, '델로네 삼각분할': 0, '도미네이터 트리': 0, '도형에서의 불 연산': 0, '두 포인터': 0, '라빈–카프': 0,
              '런타임 전의 전처리': 0, '레드-블랙 트리': 0, '로프': 0, '뤼카 정리': 0, '링크/컷 트리': 0, '많은 조건 분기': 0, '매개 변수 탐색': 0, '매내처': 0,
              '매트로이드': 0, '머지 소트 트리': 0, '모듈로 곱셈 역원': 0, '뫼비우스 반전 공식': 0, '무작위화': 0, '문자열': 0, '물리학': 0, '미적분학': 0,
              '밀러–라빈 소수 판별법': 0, '반평면 교집합': 0, '배낭 문제': 0, '백트래킹': 0, '번사이드 보조정리': 0, '벌리캠프–매시': 0, '베이즈 정리': 0,
              '벨만–포드': 0, '병렬 이분 탐색': 0, '보로노이 다이어그램': 0, '보이어–무어 다수결 투표': 0, '볼록 껍질': 0, '볼록 껍질을 이용한 최적화': 0,
              '볼록 다각형 내부의 점 판정': 0, '부분집합의 합 다이나믹 프로그래밍': 0, '분리 집합': 0, '분할 정복': 0, '분할 정복을 사용한 최적화': 0,
              '분할 정복을 이용한 거듭제곱': 0, '브루트포스 알고리즘': 0, '비둘기집 원리': 0, '비트 집합': 0, '비트마스킹': 0, '비트필드를 이용한 다이나믹 프로그래밍': 0,
              '사칙연산': 0, '삼분 탐색': 0, '생성 함수': 0, '생일 문제': 0, '서큘레이션': 0, '선분 교차 판정': 0, '선인장': 0, '선형 계획법': 0,
              '선형대수학': 0, '세그먼트 트리': 0, '센트로이드': 0, '센트로이드 분할': 0, '소수 판정': 0, '수치해석': 0, '수학': 0, '순열 사이클 분할': 0,
              '스위핑': 0, '스택': 0, '스토어–바그너': 0, '스프라그–그런디 정리': 0, '스플레이 트리': 0, '슬라이딩 윈도우': 0, '시뮬레이션': 0, '쌍대 그래프': 0,
              '쌍대성': 0, '아호-코라식': 0, '안정 결혼 문제': 0, '애드 혹': 0, '양방향 탐색': 0, '에라토스테네스의 체': 0, '연결 리스트': 0,
              '오목 다각형 내부의 점 판정': 0, '오일러 경로': 0, '오일러 경로 테크닉': 0, '오일러 지표 (χ=V-E+F)': 0, '오일러 피 함수': 0,
              '오프라인 동적 연결성 판정': 0, '오프라인 쿼리': 0, '외판원 순회 문제': 0, '우선순위 큐': 0, '위상 정렬': 0, '유클리드 호제법': 0,
              '유향 최소 신장 트리': 0, '이분 그래프': 0, '이분 매칭': 0, '이분 탐색': 0, '이산 k제곱근': 0, '이산 로그': 0, '이산 제곱근': 0,
              '이중 연결 요소': 0, '일반적인 매칭': 0, '임의 정밀도 / 큰 수 연산': 0, '자료 구조': 0, '작은 집합에서 큰 집합으로 합치는 테크닉': 0, '재귀': 0,
              '접미사 배열과 LCP 배열': 0, '접미사 트리': 0, '정규 표현식': 0, '정렬': 0, '정수론': 0, '제곱근 분할법': 0, '조합론': 0, '중간에서 만나기': 0,
              '중국인의 나머지 정리': 0, '차분 공격': 0, '차수열': 0, '최대 유량': 0, '최대 유량 최소 컷 정리': 0, '최소 공통 조상': 0, '최소 비용 최대 유량': 0,
              '최소 스패닝 트리': 0, '최소 외접원': 0, '춤추는 링크': 0, '커넥션 프로파일을 이용한 다이나믹 프로그래밍': 0, '큐': 0, '크누스 x': 0, '크누스 최적화': 0,
              '키타마사': 0, '탑 트리': 0, '통계학': 0, '트라이': 0, '트리': 0, '트리 동형 사상': 0, '트리 분할': 0, '트리 압축': 0,
              '트리를 사용한 집합과 맵': 0, '트리에서의 다이나믹 프로그래밍': 0, '파싱': 0, '퍼시스턴트 세그먼트 트리': 0, '페르마의 소정리': 0, '평면 그래프': 0,
              '포함 배제의 원리': 0, '폴라드 로': 0, '플로이드–워셜': 0, '피타고라스 정리': 0, '픽의 정리': 0, '하켄부시 게임': 0, '함수 개형을 이용한 최적화': 0,
              '함수형 그래프': 0, '해 구성하기': 0, '해시를 사용한 집합과 맵': 0, '해싱': 0, '헝가리안': 0, '현 그래프': 0, '홀의 결혼 정리': 0, '확률론': 0,
              '확장 유클리드 호제법': 0, '회문 트리': 0, '회전하는 캘리퍼스': 0, '휴리스틱': 0, '희소 배열': 0, '히르쉬버그': 0, 'centroid': 0}



def takeAlgorithm(number):
    url = f'https://solved.ac/api/v3/problem/show'
    headers = {'Content-Type': 'application/json'}
    querystring = {"problemId": number}

    req = requests.get(url, headers=headers, params=querystring)
    if req.status_code == 200:
        data = json.loads(req.text).get("tags")
        for item in data:
            algorithms[item.get('displayNames')[0].get('name')] += 1


def getUrlFromPage(tier, page):
    print(f"하는중, {page}\n")
    llist = []
    url = f'https://www.acmicpc.net/problemset?sort=no_asc&tier={tier}&page={page}'
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36'}

    req = requests.get(url, headers=headers)
    soup = BeautifulSoup(req.text, 'lxml')
    number_list = soup.select('.list_problem_id')

    for item in number_list:
        takeAlgorithm(item.get_text())


if __name__ == '__main__':
    llist = []
    getUrlFromPage(26, 3)

    print(algorithms)